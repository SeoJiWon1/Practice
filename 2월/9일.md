# [ML]
* https://colab.research.google.com/drive/1UPFnrI6zFoPfrp_z5FqSmDkC4G2krPQv?usp=sharing

1. 머신러닝 모델 성능 평가
2. 머신러닝 알고리즘에서 일반적으로 발생하는 문제 분석
3. 머신러닝 모델 세부 튜닝
4. 여러 성능 지표를 사용하여  모델의 예측 성능 평가
- 파이프라인을 사용한 효율적인 워크플로
  - 위스콘신 유방암 데이터셋
  - 파이프라인으로 변환기와 추정기 연결
- k-겹 교차 검증을 사용한 모델 성능 평가
  - 홀드아웃 방법
  - k-겹 교차 검증
- 학습 곡선과 검증 곡선을 사용한 알고리즘 디버깅
  - 학습 곡선으로 편향과 분산 문제 분석
  - 검증 곡선으로 과대적합과 과소적합 조사
- 그리드 서치를 사용한 머신 러닝 모델 세부 튜닝
  - 그리드 서치를 사용한 하이퍼파라미터 튜닝
  - 중첩 교차 검증을 사용한 알고리즘 선택
- 여러 가지 성능 평가 지표
  - 오차 행렬
  - 분류 모델의 정밀도와 재현율 최적화
  - ROC 곡선 그리기
  - 다중 분류의 성능 지표
- 불균형한 클래스 다루기

- 정밀도와 재현율 F1

# [DL]
* https://colab.research.google.com/drive/1XEJ3nQYeEmBAShGaDvQxOkv42fhFo4rj?usp=sharing
* ## 1. 데이터를 사용한 성능 최적화
### 1.1 많은 데이터 수집
  - 딥러닝 ,머신 러닝은 일반적으로 데이터 양이 많을 수록 성능이 좋다.
### 1.2 임의 데이터 생성
### 1.3 데이터 범위(scale) 조정
 - 시그모이드 활성화 함수 사용 시 데이터셋 범위를 0 ~ 1 사이가 되도록 함
 - tanh 함수 사용 시 데이터셋 범위를 1 ~ -1 사이가 되도록 함
### 1.4 정규화, 규제화, 표준화
## 2. 알고리즘을 이용한 성능 최적화
### 비슷한 용도의 알고리즘들을 선택하여 모델 훈련 후 최적의 성능을 보이는 알고리즘 선택
 - 데이터 분류: SVM, KNN 등
 - 시계열 데이터 : RNN, LSTM, GRU 등
## 3. 알고리즘 튜닝을 통한 성능 최적화
 - 성능 최적화에 가장 많이 시간 소요
 - 다양한 파라미터를 변경하면서 훈련시키고 최적의 성능 도출
 ### 선택 가능한 하이퍼파라미터
    - 진단:
        - 모델에 대한 평가(성능 진단)를 바탕으로 모델이 과적합(over fitting)인지, 다른 원인인지 통찰 가능
        - 훈련(train) 성능이 검증(test)보다 눈에 띄게 좋다면 과적합 의심. 규제화로 성능 향상
        - 훈련, 검증 결과 모두 좋지 않다면 과소적합 의심. 네트워크 구조 변경 또는 epoch 수 조정
    - 가중치:
        - 가중치 초기값을 작은 난수를 사용하여 사전 훈련(오토인코더 같은 비지도 학습을 이용하여 가중치 정보를 얻기 위한 사전 훈련)을 진행한 후 지도학습을 진행
    - 학습률(learning rate):
        - 모델의 네트워크 구성에 따라 다르므로 초기에 매우 크거나 작은 난수를 선택하여 학습 결과를 관찰하면서 조금씩 변경.
        - 네트워크 계층이 많으면 학습률을 높게, 적으면 학습률은 작게 설정.
    - 활성화 함수:
        - 활성화 함수 변경시 손실 함수도 함꼐 변경해야 하는 경우가 많으므로 신중하게 한다.
        - 활성화 함수로 시그모이드, tanh 함수 사용했을 경우, 출력층에서는 소프트맥스 또는 시그모이드 함수 많이 선택
    - 배치(batch)와 epoch:
        - 일반적으로 큰 에포크와 작은 배치 사용이 일반적.
        - 적절한 배치 크기를 위해 훈련 데이터셋의 크기와 같게 하거나 하나의 배치로 훈련해 보는 등 다양한 테스트 시도
    - 옵티마이저 및 손실 함수:
        - 일반적으로 stochatic gradient descent 많이 사용.
        - 네트워크 구성에 따라 Adam, RMSProp등도 좋은 성능 보임.
        - 다양한 옵티마이저와 손실함수 적용 후 성능이 가장 좋은 것 선택
    - 네트워크 구성(Network topology):
        - 최적의 네트워크 구성을 위해 구성을 변경해 가면서 테스트.
        - 하나의 은닉층에 뉴런을 여러개  포함시키거나(넓은 네트워크), 네트워크 계층을 늘리되 뉴런 개수를 줄인다(깊은 네트워크).
        - 혹은 두가지를 결합하는 방식으로 최적의 네트워크가 결정
## 4. 앙상블을 이용한 네트워크 최적화
### 간단한 모델을 두개 이상 섞어서 사용.
### 알고리즘 튜닝을 위한 성능 최적화 방법은 하이퍼파라미터에 대한 모든 경우의 수를 고려해야 하므로 모델 훈련이 수십, 수백번 필요할 수있다.
### 수많은 시행착오 필요.
## 5. 하이퍼 파라미터를 이용한 성능 최적화
### 배치 정규화를 통한 성능 최적화
    - 정규화(Nomalization)
    - 규제화(Regularization)
    - 표준화(Standardization)
    - 배치 정규화(Batch nomalization)
### 드롭 아웃
### 조기 종료
